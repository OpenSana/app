# OpenSana â€“ Offline-First Health Data Platform

## Overview
OpenSana is an open-source platform for collecting, analyzing, and visualizing public health data in low-resource environments.
It works without internet, runs on Raspberry Pi, and integrates with DHIS2, FHIR, and OpenMRS.

## Repository
[GitHub Link](https://github.com/opensana/app)

## Project Structure

```
opensana/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ data_cache.py       # Local data caching for offline mode
â”‚   â””â”€â”€ sync_client.py      # Data sync when internet is available
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ etl_pipeline.py # ETL pipeline using Apache Airflow
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ airflow_config.py # Airflow settings
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py              # Dash dashboard entry point
â”‚   â””â”€â”€ visualize.py        # Visualization logic with Plotly
â”œâ”€â”€ integrations/
â”‚   â”œâ”€â”€ dhis2.py            # DHIS2 API integration
â”‚   â”œâ”€â”€ fhir.py             # FHIR standards support
â”‚   â””â”€â”€ openmrs.py          # OpenMRS system integration
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py         # Global application settings
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_data.csv     # Sample dataset for testing
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run.sh              # Raspberry Pi launch script
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ main.py                 # Application entry point
```

---

## âš™ï¸ Installation on Raspberry Pi

### 1. Clone the repository:
```
bash
git clone https://github.com/opensana/app.git 
cd opensana
```
### 2. Install dependencies and run:
```
chmod +x scripts/run.sh
./scripts/run.sh
```
âœ… This script: 
  - Creates required directories (data/cache/, data/local_input/)
  - Installs Python packages from requirements.txt
  - Initializes Airflow database
  - Starts Airflow scheduler in background
  - Launches Dash dashboard on port 8050
  - Runs offline sync client

## ğŸ§© What Needs Implementation (for future PRs)
| FILE  | TASK |
| ------------- | ------------- |
| main.py  | Import modules from ```config/settings.py```  |
| main.py  | Handle DAGBag initialization errors  |
| main.py  | Run components in background processes  |
| airflow/dags/etl_pipeline.py  | Implement data processing logic  |
| airflow/dags/etl_pipeline.py  | Add ```CSV/JSON``` support from ```data/local_input/```  |
| airflow/dags/etl_pipeline.py  | Save processed data to ```data/processed/```  |
| dashboard/app.py  | Add login/auth for local dashboard  |
| dashboard/app.py  | Enable chart export as ```PNG/PDF```  |
| dashboard/app.py  | Support dynamic data reloading  |
| dashboard/visualize.py  | Add map/heatmap/table chart types  |
| dashboard/visualize.py  | Improve mobile responsiveness  |
| dashboard/visualize.py  | Add visual export options  |
| backend/data_cache.py  | Implement encrypted local storage  |
| backend/data_cache.py  | Add cache expiration policy  |
| backend/data_cache.py  | Add caching logic unit tests  |
| backend/sync_client.py  | Add sync retry logic  |
| backend/sync_client.py  | Implement batch sync for large datasets  |
| backend/sync_client.py  | Add sync attempt logging  |
| integrations/dhis2.py  | Add full DHIS2 CRUD support  |
| integrations/dhis2.py  | Implement metadata sync  |
| integrations/dhis2.py  | Add API change error handling  |
| integrations/fhir.py  | Add FHIR resource validation  |
| integrations/fhir.py  | Implement smart search/filtering  |
| integrations/fhir.py  | Add FHIR bundle support  |
| integrations/openmrs.py  | Add patient/observation sync  |
| integrations/openmrs.py  | Implement offline sync queue  |
| integrations/openmrs.py  | Support legacy OpenMRS versions  |
| airflow/config/airflow_config.py  | Add SQLite â†’ PostgreSQL switch  |
| airflow/config/airflow_config.py  | Implement DAG versioning  |
| airflow/config/airflow_config.py  | Add logging configuration  |
| config/settings.py  | Add ```.env``` file support  |
| config/settings.py  | Add configurable sync interval  |
| config/settings.py  | Implement device ID auto-generation  |
| scripts/run.sh  | Add missing file error handling  |
| scripts/run.sh  | Add auto-restart on failure  |
| scripts/run.sh  | Implement log rotation  |

## ğŸ“Š How to Use
1. Add CSV files to data/local_input/
2. DAGs will process them automatically
3. Open dashboard at http://localhost:8050
4. Data will sync via backend/sync_client.py when internet becomes available

## ğŸ¤ Contributing
All contributions are welcome!
Fork the project and submit a PR with your changes.
Use the task list above to find a starting point.

## ğŸ“„ License
MIT License
See LICENSE for details.
